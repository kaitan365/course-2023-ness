{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import mquantiles\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom quantile regression models from the mfpi folder\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from mfpi import qr_models as qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "In this workbook, we will use a data set about blog posts.\n",
    "This dataset was taken from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/BlogFeedback).\n",
    "\n",
    "The task associated with the data is the prediction of the number of comments in the upcoming 24 hours.\n",
    "In order to simulate this situation, we choose a basetime (in the past) and select the blog posts that were published at most 72 hours before the selected base date/time.\n",
    "Then, we calculate all the features of the selected blog posts from the information that was available at the basetime, therefore each instance corresponds to a blog post.\n",
    "The target is the number of comments that the blog post received in the next 24 hours relative to the basetime.\n",
    "\n",
    "In the data loaded below, the basetimes were in the years 2010 and 2011. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = pd.read_csv('../data/blogData_train.csv', header=None)\n",
    "dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is a bit too large to conveniently run in this tutorial. So, let's make it smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Throw away most of the data to speed things up\n",
    "_, dataset = train_test_split(dataset_full, test_size=1000, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a test set\n",
    "\n",
    "We consider the problem of predicting Y | X.\n",
    "\n",
    "We will hold out some of the observations for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(2023)\n",
    "\n",
    "# Designate a test set\n",
    "X_data, X_test, Y_data, Y_test = train_test_split(dataset.iloc[:,0:280].values, dataset.iloc[:,-1].values, test_size=0.2, random_state=2023)\n",
    "\n",
    "print(\"Number of explanatory variables: {:d}.\".format(X_data.shape[1]))\n",
    "print(\"Number of data points: {:d}.\".format(X_data.shape[0]))\n",
    "print(\"Number of test points: {:d}.\".format(len(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most blog receive few or no comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y_data)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Y\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning predictions\n",
    "\n",
    "We can try to predict Y | X using a deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the deep neural network\n",
    "from mfpi.deep_regression import Net as PyTorchNet\n",
    "\n",
    "black_box = PyTorchNet(X_data.shape[1], dropout=0, learning_rate=0.01,\n",
    "                       num_epochs=1000, batch_size=256, num_hidden=256, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the black-box model on all data points\n",
    "black_box.fit(X_data, Y_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "Y_hat = black_box.predict(X_test)\n",
    "Y_hat_train = black_box.predict(X_data)\n",
    "\n",
    "# Compare test points to predicted values\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "y_min = np.minimum(np.min(Y_hat_train),np.min(Y_data))\n",
    "y_max = np.maximum(np.max(Y_hat_train),np.max(Y_data))\n",
    "plt.plot([y_min, y_max], [y_min, y_max], color = 'black', linewidth = 1)\n",
    "plt.scatter(Y_data, Y_hat_train)\n",
    "plt.axis('square')\n",
    "plt.xlabel(\"True Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.title(\"Training data\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "y_min = np.minimum(np.min(Y_hat),np.min(Y_test))\n",
    "y_max = np.maximum(np.max(Y_hat),np.max(Y_test))\n",
    "plt.plot([y_min, y_max], [y_min, y_max], color = 'black', linewidth = 1)\n",
    "plt.scatter(Y_test, Y_hat)\n",
    "plt.axis('square')\n",
    "plt.xlabel(\"True Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.title(\"Test data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of in-sample and out-of-sample residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals on data and test data\n",
    "residuals_data = Y_data - black_box.predict(X_data)\n",
    "residuals_test = Y_test - black_box.predict(X_test)\n",
    "\n",
    "# Plot the absolute residuals\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(np.abs(residuals_data), alpha=0.5, bins=10)\n",
    "plt.xlabel(\"Absolute residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Training data\")\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.hist(np.abs(residuals_test), alpha=0.5, bins=10)\n",
    "plt.xlabel(\"Absolute residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive prediction intervals based on in-sample residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_prediction_intervals(X, Y, X_test, black_box, alpha):\n",
    "    \"\"\"\n",
    "    Compute naive prediction bands based on the distribution of\n",
    "      residuals within the training data set\n",
    "      \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    black_box.fit(X, Y)\n",
    "    \n",
    "    # Compute residuals on the training data\n",
    "    residuals_calib = np.abs(Y - black_box.predict(X))\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    n_calib = len(Y)\n",
    "    level_adjusted = 1.0-alpha\n",
    "    Q_hat = mquantiles(residuals_calib, prob=level_adjusted)[0]\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    Y_hat = black_box.predict(X_test)\n",
    "    lower = Y_hat - Q_hat\n",
    "    upper = Y_hat + Q_hat\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(lower, upper, X, Y, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate performance metrics for a set of regression predictions\n",
    "    Computes:\n",
    "    - marginal coverage\n",
    "    - average size of sets\n",
    "    \n",
    "    Input\n",
    "    lower     : n x 1 vector of prediction lower bounds\n",
    "    upper     : n x 1 vector of prediction upper upper\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Evaluate the empirical coverage\n",
    "    covered = (Y>=lower) * (Y <= upper)\n",
    "\n",
    "    # Compute marginal coverage\n",
    "    marginal_coverage = np.mean(covered)\n",
    "    \n",
    "    # Compute average size of prediction sets\n",
    "    size = np.mean(upper-lower)\n",
    "    \n",
    "    # Compute average size of prediction sets that contain the true label\n",
    "    idx_cover = np.where(covered)[0]\n",
    "    size_cover = np.mean(upper[idx_cover]-lower[idx_cover])\n",
    "    \n",
    "    # Print summary\n",
    "    if verbose:\n",
    "        print('Marginal coverage       : {:2.3%}'.format(marginal_coverage))\n",
    "        print('Average length          : {:2.3f}'.format(size))\n",
    "        \n",
    "    return marginal_coverage, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower, upper = naive_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal prediction via conditional mean regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Choose a black-box machine learning model (1,2,3,4,5)\n",
    "bb_model_index = 1\n",
    "\n",
    "if bb_model_index==1:\n",
    "    # Random forest\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=10, random_state=2023)\n",
    "elif bb_model_index==2:\n",
    "    # Random forest with more aggressive splits\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=1, random_state=2023)\n",
    "elif bb_model_index==3:\n",
    "    # Support vector machine\n",
    "    black_box = SVR(kernel='rbf', degree=3)\n",
    "elif bb_model_index==4:\n",
    "    # Standard scikit-learn neural network\n",
    "    black_box = MLPRegressor(hidden_layer_sizes=(200,), max_iter=1000, random_state=2023)\n",
    "elif bb_model_index==5:\n",
    "    # Custom PyTorch neural network\n",
    "    black_box = PyTorchNet(X_data.shape[1], dropout=0, learning_rate=0.01,\n",
    "                           num_epochs=1000, batch_size=256, num_hidden=256, random_state=2023)\n",
    "else:\n",
    "    print(\"Error: unknown machine learning model\")\n",
    "    black_box = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_prediction_intervals(X, Y, X_test, black_box, alpha, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute conformal prediction bands\n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : sklearn model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    X_train, X_calib, Y_train, Y_calib = train_test_split(X, Y, test_size=0.5, random_state=2023)\n",
    "    \n",
    "    # Fit the black box model on the training data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute residuals on the calibration data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply split conformal\n",
    "lower, upper = conformal_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "\n",
    "# Evaluate the predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal prediction via quantile regression\n",
    "\n",
    "Alternatively, we already know how to construct predictive intervals with valid marginal coverage using CQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mfpi.deep_quantile_regression import QNet as PyTorchQNet\n",
    "\n",
    "# Choose a black-box quantile regression model (1, 2, or 3)\n",
    "bb_qr_model_index = 3\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "if bb_qr_model_index==1:\n",
    "    # Linear quantile regression model\n",
    "    black_box_qr = qr.LinearQR(alpha=0.1)\n",
    "elif bb_qr_model_index==2:\n",
    "    # Quantile random forest\n",
    "    black_box_qr = qr.RFQR()\n",
    "elif bb_qr_model_index==3:   \n",
    "    # Quantile neural network\n",
    "    black_box_qr = PyTorchQNet([alpha/2,1-alpha/2], X_data.shape[1], no_crossing=True, \n",
    "                               dropout=0, learning_rate=0.01,\n",
    "                               num_epochs=1000, batch_size=256, num_hidden=256, random_state=2023, \n",
    "                               calibrate=0, progress=True, verbose=False)\n",
    "else:\n",
    "    print(\"Error: unknown quantile regression model\")\n",
    "    black_box_qr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cqr_prediction_intervals(X, Y, X_test, black_box, alpha, random_state=2023):\n",
    "    \"\"\"\n",
    "    Compute split-conformal quantile regression prediction bands.\n",
    "    Uses quantile random forests as a black box \n",
    "    \n",
    "    Input\n",
    "    X         : n x p data matrix of explanatory variables\n",
    "    Y         : n x 1 vector of response variables\n",
    "    X_test    : n x p test data matrix of explanatory variables\n",
    "    black_box : quantile regression model object with 'fit' and 'predict' methods\n",
    "    alpha     : 1 - target coverage level \n",
    "    \"\"\"\n",
    "    \n",
    "    # Output placeholder\n",
    "    lower = None\n",
    "    upper = None\n",
    "    \n",
    "    # Split the data into training and calibration sets\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Fit the quantile regression model\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "\n",
    "    # Estimate conditional quantiles for calibration set\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute conformity scores on the calibration data\n",
    "    \"\"\"TODO: write your code here (1 line)\"\"\"\n",
    "    \n",
    "    # Compute suitable empirical quantile of absolute residuals\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    # Construct prediction bands\n",
    "    \"\"\"TODO: write your code here (3 lines)\"\"\"\n",
    "    \n",
    "    return lower, upper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired coverage level (1-alpha)\n",
    "alpha = 0.1\n",
    "\n",
    "# Apply quantile regression split conformal\n",
    "lower, upper = cqr_prediction_intervals(X_data, Y_data, X_test, black_box_qr, alpha)\n",
    "\n",
    "# Evaluate performance of predictions\n",
    "metrics = evaluate_predictions(lower, upper, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments\n",
    "\n",
    "We will now repeatedly apply the two methods described above to the data set, each time using a different random subset of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a black-box machine learning model (1,2,3,4)\n",
    "bb_model_index = 1\n",
    "\n",
    "if bb_model_index==1:\n",
    "    # Random forest\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=10, random_state=2023)\n",
    "elif bb_model_index==2:\n",
    "    # Random forest with more aggressive splits\n",
    "    black_box = RandomForestRegressor(n_estimators=100, min_samples_split=1, random_state=2023)\n",
    "elif bb_model_index==3:\n",
    "    # Support vector machine\n",
    "    black_box = SVR(kernel='rbf', degree=3)\n",
    "elif bb_model_index==4:\n",
    "    # Standard scikit-learn neural network\n",
    "    black_box = MLPRegressor(hidden_layer_sizes=(200,), max_iter=1000, random_state=2023)\n",
    "elif bb_model_index==5:\n",
    "    # Custom PyTorch neural network\n",
    "    black_box = PyTorchNet(X_data.shape[1], dropout=0, learning_rate=0.01,\n",
    "                           num_epochs=1000, batch_size=256, num_hidden=256, progress=False, verbose=False, random_state=2023)\n",
    "else:\n",
    "    print(\"Error: unknown machine learning model\")\n",
    "    black_box = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a black-box quantile regression model (1, 2, or 3)\n",
    "bb_qr_model_index = 2\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "if bb_qr_model_index==1:\n",
    "    # Linear quantile regression model\n",
    "    black_box_qr = qr.LinearQR(alpha=0.1)\n",
    "elif bb_qr_model_index==2:\n",
    "    # Quantile random forest\n",
    "    black_box_qr = qr.RFQR()\n",
    "elif bb_qr_model_index==3:   \n",
    "    # Quantile neural network\n",
    "    black_box_qr = PyTorchQNet([alpha/2,1-alpha/2], X_data.shape[1], no_crossing=True, \n",
    "                               dropout=0, learning_rate=0.01,\n",
    "                               num_epochs=1000, batch_size=256, num_hidden=256, random_state=2023, \n",
    "                               calibrate=0, progress=False, verbose=False)\n",
    "else:\n",
    "    print(\"Error: unknown quantile regression model\")\n",
    "    black_box_qr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset, black_box, black_box_qr, random_state=2023):\n",
    "    # Divide data\n",
    "    X_data, X_test, Y_data, Y_test = train_test_split(dataset.iloc[:,0:280].values, dataset.iloc[:,-1].values, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    \n",
    "    # Run and evaluate naive\n",
    "    lower_naive, upper_naive = naive_prediction_intervals(X_data, Y_data, X_test, black_box, alpha)\n",
    "    metrics_naive = evaluate_predictions(lower_naive, upper_naive, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Run and evaluate conformal\n",
    "    lower_conformal, upper_conformal = conformal_prediction_intervals(X_data, Y_data, X_test, black_box, alpha, random_state=random_state)\n",
    "    metrics_conformal = evaluate_predictions(lower_conformal, upper_conformal, X_test, Y_test, verbose=False)\n",
    "    \n",
    "    # Run and evaluate CQR\n",
    "    lower_cqr, upper_cqr = cqr_prediction_intervals(X_data, Y_data, X_test, black_box_qr, alpha, random_state=random_state)\n",
    "    metrics_cqr = evaluate_predictions(lower_cqr, upper_cqr, X_test, Y_test, verbose=False)\n",
    "       \n",
    "    # Return results\n",
    "    results_exp = pd.DataFrame({\"Method\":[\"Naive\", \"Conformal\", \"CQR\"], \n",
    "                                \"Coverage\":[metrics_naive[0], metrics_conformal[0], metrics_cqr[0]],\n",
    "                                \"Length\":[metrics_naive[1], metrics_conformal[1], metrics_cqr[1]],\n",
    "                  })\n",
    "    \n",
    "    return results_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run many experiments\n",
    "results = pd.DataFrame()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for experiment in tqdm(range(20)):\n",
    "    \n",
    "    # Random state for this experiment\n",
    "    random_state = 2023 + experiment\n",
    "    \n",
    "    # Run the experiment\n",
    "    result_exp = run_experiment(dataset, black_box, black_box_qr, random_state=random_state)\n",
    "    \n",
    "    # Store results\n",
    "    results = pd.concat([results,result_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Prepare to make side-to-side plots\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "# Compare marginal coverage\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.boxplot(y=\"Coverage\", x=\"Method\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Marginal coverage')\n",
    "ax.axhline(1-alpha, ls='--', color=\"red\")\n",
    "\n",
    "# Compare average length of prediction intervals\n",
    "plt.subplot(1, 2, 2)\n",
    "ax = sns.boxplot(y=\"Length\", x=\"Method\", hue=\"Method\", data=results)\n",
    "ax.set(xlabel='Method', ylabel='Size of prediction intervals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
